#For final model, function chose  K=23 with highest accuracy of 83.97%
knnPredict <- predict(knnFit, newdata = testing)
confusionMatrix(knnPredict, testing$R1)
confusionMatrix(knnPredict, testing$R1)
confusionMatrix(knnPredict, as.factor(testing$R1))
con<-confusionMatrix(knnPredict, as.factor(testing$R1))
View(con)
con$overall$accuracy
con$overall$
con$overall
con$overall
type(con$overall)
d<-con$overall
View(knnFit)
type(d)
d["Accuracy"]
con
overall_accuracy<-con$overall["Accuracy"]
overall_accuracy
#Q3.1.a
set.seed(100)
#Q3.1.b
index_sample<- sample(1:nrow(data), as.integer(0.75*nrow(data)))
train_data <- Data[index_sample,]
train_data <- data[index_sample,]
valid_test_data <- data[-index_sample,]
index_sample2<- sample(1:nrow(data), as.integer(0.75*nrow(data)))
#Assigning validation and test data
valid_test_data <- data[-index_sample,]
index_sample2<- sample(1:nrow(valid_test_data), as.integer(0.50*nrow(valid_test_data)))
validation_data<-valid_test_data[index_sample2,]
testing_data<- valid_test_data[-index_sample2]
testing_data<- valid_test_data[-index_sample2,]
c_value <- seq(0, 1, by=0.1)
for(i in range(0,nrow(c_value))){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
library(kernlab)
c_value <- seq(0, 1, by=0.1)
accuracy1= rep(0,10)
for(i in range(0,nrow(c_value))){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
accuracy1= rep(1,10)
for(i in 1:nrow(c_value)){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
accuracy1= rep(1,10)
length(c_value)
for(i in 1:11){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
c_value <- seq(0, 1, by=0.1)
accuracy1= rep(1,10)
for(i in 1:11){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
c_value <- seq(0, 1, by=0.1)
accuracy1= rep(1,10)
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
c_value[1]
c_value <- seq(0.1, 1, by=0.1)
accuracy1= rep(1,10)
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
accuracy1
#which model maximizes
max_ind<-which.max()
#which model maximizes
max_ind<-which.max(accuracy1)
max_ind
c_value[1]
c_value <- seq(0.05, 1, by=0.05)
accuracy1= rep(1,20)
for(i in 1:20){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
accuracy1
#which model maximizes
max_ind<-which.max(accuracy1)
max_ind
c_value <- seq(0.01, 0.1, by=0.01)
accuracy1= rep(1,10)
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
accuracy1
#which model maximizes
max_ind<-which.max(accuracy1)
max_ind
c_value <- seq(0.1, 1, by=0.1)
accuracy1= rep(1,10)
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
accuracy1
#which model maximizes
max_ind<-which.max(accuracy1)
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
print(c_value)
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
print(c_value)
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
print(c_value[i])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
}
accuracy1
print(accuracy[i])
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
print(accuracy[i])
}
for(i in 1:10){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
print(accuracy1[i])
}
c_value <- seq(1, 100, by=5)
accuracy1= rep(1,20)
for(i in 1:20){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
print(accuracy1[i])
}
accuracy1
#c_value <- seq(1, 100, by=5)
c_value= c(50,100,1000)
accuracy1= rep(1,3)
for(i in 1:3){
svm_model<- ksvm(as.matrix(train_data[,1:10]), as.factor(train_data[,11]), type="C-svc", kernel = "vanilladot", C=c_value[i], scaled=TRUE)
prediction = predict(svm_model, validation_data[,1:10])
accuracy1[i] = sum(prediction==validation_data$R1)/nrow(validation_data)
print(accuracy1[i])
}
for (i in 1:3) {
#Now, fitting model using training dataset by using C-classification method and simple linear kernel (vanilladot)
creditcardmodel_scaled = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C = c_value[i],scaled=TRUE)
# Model prediction
pred = predict(creditcardmodel_scaled,validation_data[,1:10])
#How much model`s prediction actually match the actual classification`
accuracy1[i] = (sum(pred == validation_data$R1) / nrow(creditcard_validation))*100
}
for (i in 1:3) {
#Now, fitting model using training dataset by using C-classification method and simple linear kernel (vanilladot)
creditcardmodel_scaled = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C = c_value[i],scaled=TRUE)
# Model prediction
pred = predict(creditcardmodel_scaled,validation_data[,1:10])
#How much model`s prediction actually match the actual classification`
accuracy1[i] = (sum(pred == validation_data$R1) / nrow(validation_data))*100
}
accuracy1
data<-read.table("credit_card_data-headers.txt", header = TRUE)
data<-as.data.frame(data)
index_sample<- sample(1:nrow(data), as.integer(0.60*nrow(data)))
train_data <- data[index_sample,]
View(train_data)
#Assigning validation and test data
valid_test_data <- data[-index_sample,]
index_sample2<- sample(1:nrow(valid_test_data), as.integer(0.50*nrow(valid_test_data)))
validation_data<-valid_test_data[index_sample2,]
testing_data<- valid_test_data[-index_sample2,]
#c_value <- seq(1, 100, by=5)
c_value= c(0.01,50,100,1000)
accuracy1= rep(1,4)
for (i in 1:4) {
#Now, fitting model using training dataset by using C-classification method and simple linear kernel (vanilladot)
creditcardmodel_scaled = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C = c_value[i],scaled=TRUE)
# Model prediction
pred = predict(creditcardmodel_scaled,validation_data[,1:10])
#How much model`s prediction actually match the actual classification`
accuracy1[i] = (sum(pred == validation_data$R1) / nrow(validation_data))*100
}
accuracy1
#c_value <- seq(1, 100, by=5)
c_value= c(0.00001,50,100,1000)
accuracy1= rep(1,4)
for (i in 1:4) {
#Now, fitting model using training dataset by using C-classification method and simple linear kernel (vanilladot)
creditcardmodel_scaled = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C = c_value[i],scaled=TRUE)
# Model prediction
pred = predict(creditcardmodel_scaled,validation_data[,1:10])
#How much model`s prediction actually match the actual classification`
accuracy1[i] = (sum(pred == validation_data$R1) / nrow(validation_data))*100
}
accuracy1
index_sample<- sample(1:nrow(data), as.integer(0.75*nrow(data)))
train_data <- data[index_sample,]
#Assigning validation and test data
valid_test_data <- data[-index_sample,]
index_sample2<- sample(1:nrow(valid_test_data), as.integer(0.50*nrow(valid_test_data)))
validation_data<-valid_test_data[index_sample2,]
testing_data<- valid_test_data[-index_sample2,]
#c_value <- seq(1, 100, by=5)
c_value= seq(.1,1,by=0.1)
#c_value <- seq(1, 100, by=5)
c_value= seq(.1,1,by=0.1)
accuracy1= rep(1,10)
for (i in 1:10) {
#Now, fitting model using training dataset by using C-classification method and simple linear kernel (vanilladot)
creditcardmodel_scaled = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C = c_value[i],scaled=TRUE)
# Model prediction
pred = predict(creditcardmodel_scaled,validation_data[,1:10])
#How much model`s prediction actually match the actual classification`
accuracy1[i] = (sum(pred == validation_data$R1) / nrow(validation_data))*100
}
#looping for accuracy for svm model for different c value with increment of 0.1, tried 1 to 100 by 5 increment already
for (i in 1:10) {
svm_model = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C = c_value[i],scaled=TRUE)
prediction1 = predict(svm_model,validation_data[,1:10])
accuracy1[i] = (sum(prediciton1 == validation_data$R1) / nrow(validation_data))*100
}
#looping for accuracy for svm model for different c value with increment of 0.1, tried 1 to 100 by 5 increment already
for (i in 1:10) {
svm_model = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C = c_value[i],scaled=TRUE)
prediction1 = predict(svm_model,validation_data[,1:10])
accuracy1[i] = (sum(prediction1 == validation_data$R1) / nrow(validation_data))*100
}
accuracy1
#which model maximizes
max_ind<-which.max(accuracy1)
#which model maximizes
max_ind<-which.max(accuracy1)
max_ind
c_value[max_ind]
max(accuracy1)
c_max<-c_value[max_ind]
cat("C value which maximizes accuracy =",c_max,"\n")
svm_model_test = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C =0.1,scaled=TRUE)
#retraining model on training dataset with parameter c=0.1
svm_model_test = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C =0.1,scaled=TRUE)
Accuracy_on_test = sum(predict(svm_model_test,testing_data[,1:10])==testing_data[,11])/nrow(testing_data)
Accuracy_on_test
cat("Accuracy on test data set =", Accuracy_on_test)
setwd("C:/Users/Muhammad/ISYE/hw3")
library(tidyverse)
library(caret)
library(kernlab)
setwd("C:/Users/Muhammad/ISYE/hw3")
data<-read.table("credit_card_data-headers.txt", header = TRUE)
data<-as.data.frame(data)
#Q3.1.a
set.seed(100)
#splitting data for training/validation and testing. 80% training data set
indxTrain <- createDataPartition(y = data$R1,p = 0.8,list = FALSE)
training <- data[indxTrain,]
testing <- data[-indxTrain,]
#Pre-processing data i.e scaling for Knn
trainX <- training[,names(training) != "R1"]
Proccessed_Values <- preProcess(x = trainX,method = c("center", "scale"))
#I am choosing k-fold value of 5 beacause our dataset is too small
control <- trainControl(method="cv",number=5)
#training data set
knnFit <- train(as.factor(R1) ~ ., data = training, method = "knn", trControl = control, preProcess = c("center","scale"), tuneLength = 50)
#finding the value of kappa where accuracy maximizes;
which.max(knnFit$results$Accuracy)
knnFit$results$Accuracy[10]
k=knnFit$results$k[10]
k
plot(knnFit)
#For final model, function chose  K=23 with highest accuracy of 83.97%
#Testing our model on test dataset
knnPredict <- predict(knnFit, newdata = testing)
con<-confusionMatrix(knnPredict, as.factor(testing$R1))
con
overall_accuracy<-con$overall["Accuracy"]
overall_accuracy
#Overall accuracy is 86.15%
#Q3.1.b
#Sampling and splitting data for training and testing
index_sample<- sample(1:nrow(data), as.integer(0.75*nrow(data)))
train_data <- data[index_sample,]
#Assigning validation and test data
valid_test_data <- data[-index_sample,]
index_sample2<- sample(1:nrow(valid_test_data), as.integer(0.50*nrow(valid_test_data)))
validation_data<-valid_test_data[index_sample2,]
testing_data<- valid_test_data[-index_sample2,]
#c_value <- seq(1, 100, by=5)
c_value= seq(.1,1,by=0.1)
accuracy1= rep(1,10)
#looping for accuracy for svm model for different c value with increment of 0.1, tried 1 to 100 by 5 increment already
for (i in 1:10) {
#training model on training data
svm_model = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C = c_value[i],scaled=TRUE)
#testing it on validation data
prediction1 = predict(svm_model,validation_data[,1:10])
accuracy1[i] = (sum(prediction1 == validation_data$R1) / nrow(validation_data))*100
}
#which model maximizes
max_ind<-which.max(accuracy1)
max(accuracy1)
c_max<-c_value[max_ind]
cat("C value which maximizes accuracy =",c_max,"\n")
#retraining model on training dataset with parameter c=0.1
svm_model_test = ksvm(as.matrix(train_data[,1:10]),as.factor(train_data[,11]), type = "C-svc",kernel = "vanilladot",C =0.1,scaled=TRUE)
Accuracy_on_test = sum(predict(svm_model_test,testing_data[,1:10])==testing_data[,11])/nrow(testing_data)
cat("Accuracy on test data set =", Accuracy_on_test)
set.seed(100)
#splitting data for training/validation and testing. 80% training data set
indxTrain <- createDataPartition(y = data$R1,p = 0.8,list = FALSE)
training <- data[indxTrain,]
testing <- data[-indxTrain,]
#Pre-processing data i.e scaling for Knn
trainX <- training[,names(training) != "R1"]
Proccessed_Values <- preProcess(x = trainX,method = c("center", "scale"))
#I am choosing k-fold value of 5 beacause our dataset is too small
control <- trainControl(method="cv",number=5)
#training data set
knnFit <- train(as.factor(R1) ~ ., data = training, method = "knn", trControl = control, preProcess = c("center","scale"), tuneLength = 50)
#finding the value of kappa where accuracy maximizes;
which.max(knnFit$results$Accuracy)
knnFit$results$Accuracy[10]
k=knnFit$results$k[10]
k
plot(knnFit)
#For final model, function chose  K=23 with highest accuracy of 83.97%
#Testing our model on test dataset
knnPredict <- predict(knnFit, newdata = testing)
con<-confusionMatrix(knnPredict, as.factor(testing$R1))
con
overall_accuracy<-con$overall["Accuracy"]
overall_accuracy
cat("Accuracy =", overall_accuracy)
cat("Accuracy =", overall_accuracy*100)
#Q4.2
library(datasets)
data_iris <-dataset(iris)
data_iris <-data(iris)
data_iris
summary(iris)
names(iris) <- tolower(names(iris))
data(iris)
names(iris) <- tolower(names(iris))
iris
View(iris)
iris_attributes <- iris[,1:4]
View(iris_attributes)
iris_category <- iris[,5]
iris_category
iris_category <- unique(iris[,5])
iris
iris_category
iris_category <- unique(iris[,5])
iris_category
iris_X_data <- scale(iris[,1:4])
kmeans(iris_X_data, 3, nstart = 100)
#Example
par(mfrow=c(2,1))
plot(iris.new[c(1,2)], col=result$cluster)
model1<-kmeans(iris_X_data, 3, nstart = 100)
model1
#Example of visualizing two features
par(mfrow=c(2,1))
plot(iris_X_data[c(1,2)], col=model1$cluster)
plot(iris_X_data[c(1,2)], col=iris_category)
#Example of visualizing two features
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris_X_data[c(1,2)], col=model1$cluster)
plot(iris_X_data[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3, nstart = 100)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris_X_data[c(1,2)], col=model1$cluster)
plot(iris_X_data[c(1,2)], col=iris_category)
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3, nstart = 20)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3, nstart = 10)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3, nstart = 5)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3, nstart = 3)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3, nstart = 3)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3, nstart = 1)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
model_kmean<-kmeans(iris[,1:4], 3, nstart = 20)
model_kmean
par(mfrow=c(2,1), mar=c(5,4,2,2))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
par(mfrow=c(2,1))
plot(iris[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
preproc2 <- preProcess(iris[,1:4], method=c("range"))
normalized_data <- predict(preproc2, dat[,1:4])
normalized_data <- predict(preproc2, iris[,1:4])
View(normalized_data)
model_kmean<-kmeans(normalized_data[,1:4], 3, nstart = 20)
model_kmean
plot(normalized_data[c(1,2)], col=model_kmean$cluster)
plot(normalized_data[c(1,2)], col=iris_category)
plot(iris[c(1,2)], col=iris_category)
plot(normalized_data[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
par(mfrow=c(2,1))
plot(normalized_data[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
names(iris) <- tolower(names(iris))
iris_category <- unique(iris[,5])
#Scaling all data set
preproc2 <- preProcess(iris[,1:4], method=c("range"))
normalized_data <- predict(preproc2, iris[,1:4])
model_kmean<-kmeans(normalized_data[,1:4], 3, nstart = 20)
model_kmean
#i.e:
par(mfrow=c(2,1))
plot(normalized_data[c(1,2)], col=model_kmean$cluster)
plot(iris[c(1,2)], col=iris_category)
cat("For final model Accuracy =", knnFit$results$Accuracy[index_where_max], "and k =",k)
library(caret)
library(kernlab)
setwd("C:/Users/Muhammad/ISYE/hw3")
data<-read.table("credit_card_data-headers.txt", header = TRUE)
data<-as.data.frame(data)
#Q3.1.a
set.seed(100)
#splitting data for training/validation and testing. 80% training data set
indxTrain <- createDataPartition(y = data$R1,p = 0.8,list = FALSE)
training <- data[indxTrain,]
testing <- data[-indxTrain,]
#Pre-processing data i.e scaling for Knn
trainX <- training[,names(training) != "R1"]
Proccessed_Values <- preProcess(x = trainX,method = c("center", "scale"))
control <- trainControl(method="cv",number=5)
#training data set
knnFit <- train(as.factor(R1) ~ ., data = training, method = "knn", trControl = control, preProcess = c("center","scale"), tuneLength = 50)
#finding the value of kappa where accuracy maximizes;
index_where_max<-which.max(knnFit$results$Accuracy)
knnFit$results$Accuracy[index_where_max]
k=knnFit$results$k[index_where_max]
k
plot(knnFit)
cat("For final model Accuracy =", knnFit$results$Accuracy[index_where_max], "and k =",k)
plot(normalized_data[c(1,2)], col=model_kmean$cluster)
plot(normalized_data[c(1,2)], col=model_kmean$cluster)
library(knitr)
